{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%config SqlMagic.autocommit=False\n",
    "%sql mysql+pymysql://root:root@127.0.0.1:3306/mysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create a __structure__ with the __data of \"Germplasm.tsv\" and \"LocusGene.tsv\"__ with the purpose of not opening and closing the file or redirecting the pointer constantly, and this way we can work with indexes instead.\n",
    "\n",
    "These data structures are going to be used in several problems.\n",
    "\n",
    "This approach is useful if the data in the files is short, i.e., it __can be stored in the RAM__, which is the case. \n",
    "\n",
    "Otherwise, another approach will be better or needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data_germplasm = []\n",
    "data_locusgene = []\n",
    "\n",
    "with open(\"../Germplasm.tsv\",\"r\") as germplasm:\n",
    "    germplasm_dict = csv.DictReader(germplasm, delimiter = \"\\t\") #If we skip the fieldname parameter the first row is assumed to be the fieldnames\n",
    "    for line in germplasm_dict:\n",
    "            data_germplasm.append(line)\n",
    "    germplasm.close()\n",
    "\n",
    "with open(\"../LocusGene.tsv\",\"r\") as locusgene:\n",
    "    locusgene_dict = csv.DictReader(locusgene, delimiter = \"\\t\")\n",
    "    for line_1 in locusgene_dict:\n",
    "            data_locusgene.append(line_1)\n",
    "    locusgene.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have __loaded__ the files into lists in which every element is a line.\n",
    "\n",
    "Let's do some __pre-processing__ of the data so we have it prepared for the problems, due to the fact that everything is read as a string, and there are fields in the data that are supposed to be integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in data_germplasm:\n",
    "    line[\"pubmed\"] = int(line[\"pubmed\"])\n",
    "for line_1 in data_locusgene:\n",
    "    line_1[\"ProteinLength\"] = int(line_1[\"ProteinLength\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the structure of the list elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_germplasm[0])\n",
    "print(data_locusgene[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "\n",
    "\n",
    "</pre>\n",
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, line in enumerate(data_germplasm):\n",
    "    if line[\"Locus\"] == data_locusgene[i][\"Locus\"]:\n",
    "        continue\n",
    "    else:\n",
    "        print(\"Records \"+line[\"Locus\"]+\" and \"+data_locusgene[i][\"Locus\"]+\" are in the same line\")\n",
    "print(\"Everything is in order :)\") #To know that the loop has finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a __for loop__ that will go through all the element in both lists and will check if AGI locuses are in the same order.\n",
    "\n",
    "To be sure that the loop has finished and __not stuck in an infinite iteration__, we print a sentence at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "\n",
    "\n",
    "</pre>\n",
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the database\n",
    "%sql create database exam_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql.cursors\n",
    "\n",
    "# Connect to the database\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='exam_2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"create table germplasm (Locus VARCHAR(10) PRIMARY KEY, germplasm VARCHAR(50), phenotype VARCHAR(50000), pumbed INT NOT NULL)\"\n",
    "sql_2 = \"create table locusgene (Locus VARCHAR(10) PRIMARY KEY, Gene VARCHAR(10), ProteinLength INT, FOREIGN KEY(Locus) REFERENCES germplasm(Locus))\"\n",
    "cursor.execute(sql)\n",
    "cursor.execute(sql_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the database __\"exam_2\"__ with MagicSQL and then we access it via pymsql.\n",
    "\n",
    "Next, we create a connection to the previously created database and make a cursor for that connection.\n",
    "\n",
    "Finally, we create and execute the queries that will create 2 tables:\n",
    "    - \"germplasm\": it has 4 columns (Locus, germplasm, phenotype and pumbed) being Locus the primary key\n",
    "    - \"locusgene\": it has 3 columns (Locus, Gene and ProteinLength)  being Locus the primary key and a foreign key which references to germplasm.Locus. This way, if we change the name of a locus in germplasm, it will autommatically change in locusgene, preserving the integrity of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "\n",
    "\n",
    "</pre>\n",
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_db(data, table):\n",
    "    \"\"\"Function to fill any table of a DB\n",
    "    Input: list of dictionaries extracted of a csv.DictReader and the name of the DB table that we want to fill\n",
    "    Result: every element of the list data will be added to the table as a record\"\"\"\n",
    "    for line in data:\n",
    "        values_line = tuple(line.values())\n",
    "        arguments = (table,str(values_line))\n",
    "        sentence = \"INSERT INTO %s VALUES %s;\"%arguments\n",
    "        cursor.execute(sentence)    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill the germplasm table\n",
    "fill_db(data_germplasm, 'germplasm')\n",
    "#Fill the locusgene table\n",
    "fill_db(data_locusgene, \"locusgene\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a function called __\"fill_db\"__ that will take as an input a data and the name of a table, and will fill the second one with the information of the fisrt argument.\n",
    "\n",
    "We go through every line of the data, exctract the values and then create a SQL query that will introduce those values in the table.\n",
    "\n",
    "The __pro__ of this function is that is not restricted to these 2 tables that we are working with. The __con__ is that every row of the data must have an information for all the columns in the table. \n",
    "\n",
    "We could fix this problem with a __third argument__ that will determine which columns we want to introduce values into and some minor changes in the the query.\n",
    "\n",
    "Finally, we just call the function with the tables \"germplasm\" and \"locusgene\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "\n",
    "\n",
    "</pre>\n",
    "## Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_results(queries, messages, file_name):\n",
    "    output = open(file_name,\"w\")\n",
    "    output.write(\"These are the results of the Problem 4 in the Second Exam\\n\\n\")\n",
    "    for i, query in enumerate(queries):\n",
    "        output.write(str(messages[i]+\":\\n\\n\"))\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        headers = list(result[0].keys())\n",
    "        output.write(str(\"\\t\".join(headers)+\"\\n\"))\n",
    "        for row in result:\n",
    "            values = []\n",
    "            for element in list(row.values()): #This is for making the integrers and the floats to str, so the join works\n",
    "                values.append(str(element))\n",
    "            sentence = \"\\t\".join(values)\n",
    "            output.write(sentence+\"\\n\")\n",
    "        output.write(\"\\n\\n\\n\\n\") #To separate the results\n",
    "    output.close()\n",
    "    return(\"The file is created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **make_results** will take as an input a query or list of queries, a message or list of messages(every query must have its own message) and the file_name where you want to store the data.\n",
    "\n",
    "For every query it will execute it in the database and we will store the output in the variable __\"result\"__ (it is a list of dictionaries). We take the __headers__ of the output table from the keys of the first element of the list, and then, one by one, we will take the __values__ of the dictionary and write them in the file.\n",
    "\n",
    "Finally, we will write in the file some new lines for __aesthetic reasons__, and return a sentence to know that the function has finished successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"select * from locusgene, germplasm where locusgene.Locus=germplasm.Locus\"\n",
    "message_1 = \"All the data that we have for every AGI Locus in the database 'exam_2'\"\n",
    "query_2 = \"select * from locusgene,germplasm where locusgene.Locus=germplasm.Locus and locusgene.Gene IN ('MAA3','SKOR')\"\n",
    "message_2 = \"All the data that we have for genes MAA3 and SKOR in the database 'exam_2'\"\n",
    "query_3 = \"select substring(Locus,3,1) as Chromosome, count(*) as NumberGenes from germplasm group by substring(Locus,3,1)\"\n",
    "message_3 = \"Number of genes per chromosome in the database 'exam_2'\"\n",
    "query_4 = \"select substring(Locus,3,1) as Chromosome, avg(ProteinLength) as AvgProteinLength from locusgene group by substring(Locus,3,1)\"\n",
    "message_4 = \"Average protein length for the genes on each Chromosome in the database 'exam_2'\"\n",
    "\n",
    "make_results([query_1,query_2,query_3,query_4],[message_1,message_2,message_3,message_4],\"Results_Problem_4.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **query_1**: we select every column from the 2 tables of the DB when the locus from both are the same\n",
    "* **query_2**: we select every column from locusgene and germplasm when they have the same locus and the gene name is MAA3 or SKOR\n",
    "* **query_3**: we extract the third character of locus(chromosome number), we group by that chromosome and we count the number of rows that has matched for every substring (1 to 5) in the table germplasm and we rename the output columns\n",
    "* **query_4**:  e extract the third character of locus(chromosome number), we group by that chromosome and we do the average of the row values (ProteinLength is a number) that matched for every chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We __close__ the cursor and connection for the \"exam_2\" DB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
